# @package datamodule
defaults:
  - /datamodule/semantic/_features.yaml

_target_: null

data_dir: ${paths.data_dir}

# Number of classes must be specified to help instantiating the model.
# Concretely, num_classes here will be passed to the DataModule and the
# Dataset upon hydra.utils.instantiate. But it will likely be ignored by
# those. Specifying num_classes in the data config actually allows the
# model config to capture it and assign the proper model output size by
# config interpolation
num_classes: ???

# Stuff class indices are not needed for semantic segmentation but must
# be specified for instance/panoptic segmentation
stuff_classes: []

# Whether the dataset produces instance labels. In any case, the
# instance labels will be preprocessed, if any. However, `instance: False`
# will avoid unwanted instance-related I/O operations, to save memory
instance: False

# Instantiation graph parameters. These are used for instance/panoptic
# segmentation but will be skipped for semantic segmentation (ie if
# `datamodule.instance: False`)
instance_k_max: 30  # maximum number of neighbors for each superpoint in the instance graph
instance_radius: 0.1  # maximum distance of neighbors for each superpoint in the instance graph
min_instance_size: 100

# Mini dataset
# Each dataset has a 'mini' version which only uses a small portion of
# the data. Can be useful for experimentation and debugging
mini: False

# I/O parameters
save_y_to_csr: True  # save 'y' label histograms using a custom CSR format to save memory and I/O time
save_pos_dtype: 'float32'  # dtype to which 'pos' will be saved on disk
save_fp_dtype: 'float16'  # dtype to which all other floating point tensors will be saved to disk
load_non_fp_to_long: False  # non-floating-point tensors are saved with the smallest precision-preserving dtype. `load_non_fp_to_long` rules whether these should be cast back to int64 upon reading
in_memory: False

# Disk memory
# Set lite_preprocessing to only preprocess and save to disk features
# strictly needed for training, to save disk memory. If False, all
# supported point, segment features will be computed. This can be useful
# if you are experimenting with various feature combinations and do not
# want preprocessing to start over whenever testing a new combination
# If True, lite_preprocessing alleviate disk memory use and makes I/O
# faster, hence faster training and inference
lite_preprocessing: True

# Set prepare_only_test to only preprocess the test dataset. This is useful
# to run `eval.py` without needing to preprocess the train and validation sets.
prepare_only_test: False

# Full-resolution prediction
# By default, we do not need to load the full-resolution input point 
# cloud for training, validating, and testing, because we compute 
# metrics and losses based on histograms of full-resolution labels inside
# voxels and superpoints. Yet, for some inference applications, it may 
# be needed to produce a full-resolution prediction. To this end, 
# setting load_full_res_idx to True will load, for each preprocessed 
# voxel, the indices of the full-resolution points it contains. This 
# information can then be used by our model when required to produce a 
# full-resolution prediction. Leaving load_full_res_idx to False by 
# default avoids unnecessary I/O disk operations and saves RAM
load_full_res_idx: False

# GPU memory
# The following parameters are not the only ones affecting GPU memory.
# Several strategies can be deployed to mitigate memory impact, from
# batch construction to architecture size. However, these are good
# safeguard settings as a last resort to prevent our base model from OOM
# a 32G GPU at training time. May be adapted to other GPUs, models and
# training procedures
max_num_nodes: 50000
max_num_edges: 1000000

# Test-time augmentation
tta_runs: null
tta_val: False

# Produce submission data if trainer.test=true, for datasets with a
# submission process
submit: False

# DataLoader parameters. Would be good to have them live in another file
dataloader:
    batch_size: 4
    num_workers: 4
    pin_memory: True
    persistent_workers: True

# Whether the data transfer across devices must be non-blocking. This is
# ignored if the training device is "cpu" or "mps"
non_blocking: True

# Preprocessing
pre_transform:
    - transform: DataTo
      params:
        device: 'cuda'
    - transform: SaveNodeIndex
      params:
        key: 'sub'
    - transform: GridSampling3D
      params:
        size: ${datamodule.voxel}
        hist_key: 'y'
        hist_size: ${eval:'${datamodule.num_classes} + 1'}
        inplace: True
        chunk_size: 10000000  # reduce if OOM on CUDA for small GPUs
    - transform: KNN
      params:
        k: ${datamodule.knn}
        r_max: ${datamodule.knn_r}
        verbose: False
    - transform: PointFeatures
      params:
        keys: ${datamodule.point_hf_preprocess}
        k_min: 1
        k_step: ${datamodule.knn_step}
        k_min_search: ${datamodule.knn_min_search}
        overwrite: ${datamodule.point_hf_overwrite}
    - transform: GroundElevation
      params:
        model: 'ransac'
        z_threshold: ${datamodule.ground_threshold}
        xy_grid: ${datamodule.ground_xy_grid}
        scale: ${datamodule.ground_scale}
    - transform: AdjacencyGraph
      params:
        k: ${datamodule.pcp_k_adjacency}
        w: ${datamodule.pcp_w_adjacency}
    - transform: ConnectIsolated
      params:
        k: 1
    - transform: AddKeysTo  # move some features to 'x' to be used for partition
      params:
        keys: ${datamodule.partition_hf}
        to: 'x'
        delete_after: False
    - transform: CutPursuitPartition
      params:
        regularization: ${datamodule.pcp_regularization}
        spatial_weight: ${datamodule.pcp_spatial_weight}
        k_adjacency: ${datamodule.pcp_k_adjacency}
        cutoff: ${datamodule.pcp_cutoff}
        iterations: ${datamodule.pcp_iterations}
        edge_reduce: ${datamodule.pcp_edge_reduce}
        parallel: True
        verbose: False
    - transform: NAGRemoveKeys  # remove 'x' used for partition (features are still preserved under their respective Data attributes)
      params:
        level: 'all'
        keys: 'x'
    - transform: SegmentFeatures
      params:
        n_min: 32
        n_max: 128
        keys: ${datamodule.segment_base_hf_preprocess}
        mean_keys: ${datamodule.segment_mean_hf_preprocess}
        std_keys: ${datamodule.segment_std_hf_preprocess}
        strict: False  # will not raise error if a mean or std key is missing
    - transform: RadiusHorizontalGraph
      params:
        k_min: ${datamodule.graph_k_min}
        k_max: ${datamodule.graph_k_max}
        gap: ${datamodule.graph_gap}
        se_ratio: ${datamodule.graph_se_ratio}
        se_min: ${datamodule.graph_se_min}
        cycles: ${datamodule.graph_cycles}
        margin: ${datamodule.graph_margin}
        chunk_size: ${datamodule.graph_chunk}
        halfspace_filter: True
        bbox_filter: True
        target_pc_flip: True
        source_pc_sort: False
        keys: ['mean_off', 'std_off', 'mean_dist' ]
    - transform: NAGTo
      params:
        device: 'cpu'

# CPU-based train transforms
# In order to maximize dataloader throughput, we actively postpone all
# costly operations to happen on-device. If you still prefer running some
# things on CPU, be careful of what you put in here...
train_transform: null

# CPU-based val transforms
# In order to maximize dataloader throughput, we actively postpone all
# costly operations to happen on-device. If you still prefer running some
# things on CPU, be careful of what you put in here...
val_transform: ${datamodule.train_transform}

# CPU-based test transforms
# In order to maximize dataloader throughput, we actively postpone all
# costly operations to happen on-device. If you still prefer running some
# things on CPU, be careful of what you put in here...
test_transform: ${datamodule.val_transform}

# GPU-based train transforms
on_device_train_transform:

    # Cast all attributes to either float or long. Doing this only now
    # allows speeding up disk I/O and CPU->GPU transfer
    - transform: NAGCast

    # Add a `node_size` attribute to all segments, this is needed for
    # segment-wise position normalization with UnitSphereNorm
    - transform: NodeSize
      params:
        low: 0

    # Apply sampling transforms first to reduce the number of nodes and
    # edges. These operations are compute-intensive and are the reason
    # why these transforms are not performed on CPU
    - transform: SampleSubNodes
      params:
        low: 0
        high: ${eval:'0 if ${datamodule.nano} else 1'} #i.e.: skip the transform if nano
        n_min: ${datamodule.sample_point_min}
        n_max: ${datamodule.sample_point_max}
    - transform: SampleRadiusSubgraphs
      params:
        r: ${datamodule.sample_graph_r}
        k: ${datamodule.sample_graph_k}
        k_max: ${datamodule.sample_graph_max_nodes}
        i_level: 1
        by_size: False
        by_class: False
        disjoint: ${datamodule.sample_graph_disjoint}
        cylindrical: ${datamodule.sample_graph_cylindrical}
    - transform: SampleSegments
      params:
        ratio: ${datamodule.sample_segment_ratio}
        by_size: ${datamodule.sample_segment_by_size}
        by_class: ${datamodule.sample_segment_by_class}
    - transform: NAGRestrictSize
      params:
        level: '1+'
        num_nodes: ${datamodule.max_num_nodes}

    # Apply geometric transforms affecting position, offsets, normals
    # before calling transforms relying on those, such as on-the-fly
    # edge features computation
    - transform: NAGJitterKey
      params:
        key: 'pos'
        sigma: ${datamodule.pos_jitter}
        trunc: ${datamodule.voxel}
    - transform: RandomTiltAndRotate
      params:
        phi: ${datamodule.tilt_n_rotate_phi}
        theta: ${datamodule.tilt_n_rotate_theta}
    - transform: RandomAnisotropicScale
      params:
        delta: ${datamodule.anisotropic_scaling}
    - transform: RandomAxisFlip
      params:
        p: 0.5

    # Compute some horizontal and vertical edges on-the-fly. Those are
    # only computed now since they can be deduced from point and node
    # attributes. Besides, the OnTheFlyHorizontalEdgeFeatures transform
    # takes a trimmed graph as input and doubles its size, creating j->i
    # for each input i->j edge
    - transform: OnTheFlyHorizontalEdgeFeatures
      params:
        keys: ${datamodule.edge_hf}
        use_mean_normal: ${eval:'"normal" in ${datamodule.segment_mean_hf}'}
    - transform: OnTheFlyVerticalEdgeFeatures
      params:
        keys: ${datamodule.v_edge_hf}
        use_mean_normal: ${eval:'"normal" in ${datamodule.segment_mean_hf}'}

    # Edge sampling is only performed after the horizontal graph is
    # untrimmed by OnTheFlyHorizontalEdgeFeatures
    - transform: SampleEdges
      params:
        level: '1+'
        n_min: ${datamodule.sample_edge_n_min}
        n_max: ${datamodule.sample_edge_n_max}
    - transform: NAGRestrictSize
      params:
        level: '1+'
        num_edges: ${datamodule.max_num_edges}

    # Add some noise and randomly some point, node and edge features
    - transform: NAGJitterKey
      params:
        key: ${eval:'ListConfig([k for k in ${datamodule.all_point_hf} if k != "rgb"])'}
        sigma: ${datamodule.node_feat_jitter}
        trunc: ${eval:'2 * ${datamodule.node_feat_jitter}'}
    - transform: NAGJitterKey
      params:
        key: 'edge_attr'
        sigma: ${datamodule.h_edge_feat_jitter}
        trunc: ${eval:'2 * ${datamodule.h_edge_feat_jitter}'}
    - transform: NAGJitterKey
      params:
        key: 'v_edge_attr'
        sigma: ${datamodule.v_edge_feat_jitter}
        trunc: ${eval:'2 * ${datamodule.v_edge_feat_jitter}'}
    - transform: NAGDropoutColumns
      params:
        p: ${datamodule.node_feat_drop}
        key: ${eval:'ListConfig([k for k in ${datamodule.all_point_hf} if k != "rgb"])'}
        inplace: True
        to_mean: ${datamodule.drop_to_mean}
    - transform: NAGDropoutColumns
      params:
        p: ${datamodule.h_edge_feat_drop}
        key: 'edge_attr'
        inplace: True
        to_mean: ${datamodule.drop_to_mean}
    - transform: NAGDropoutColumns
      params:
        p: ${datamodule.v_edge_feat_drop}
        key: 'v_edge_attr'
        inplace: True
        to_mean: ${datamodule.drop_to_mean}
    - transform: NAGDropoutRows
      params:
        p: ${datamodule.node_row_drop}
        key: ${eval:'ListConfig([k for k in ${datamodule.all_point_hf} if k != "rgb"])'}
        to_mean: ${datamodule.drop_to_mean}
    - transform: NAGDropoutRows
      params:
        p: ${datamodule.h_edge_row_drop}
        key: 'edge_attr'
        to_mean: ${datamodule.drop_to_mean}
    - transform: NAGDropoutRows
      params:
        p: ${datamodule.v_edge_row_drop}
        key: 'v_edge_attr'
        to_mean: ${datamodule.drop_to_mean}

    # RGB-specific transforms. In particular, the color dropout will
    # switch off all three color channels together, instead of just one
    # by one with
#    - transform: NAGColorNormalize
#      params:
#        level: 'all'
    - transform: NAGJitterKey
      params:
        key: 'rgb'
        sigma: ${datamodule.rgb_jitter}
        trunc: ${eval:'2 * ${datamodule.rgb_jitter}'}
    - transform: NAGColorAutoContrast
      params:
        p: ${datamodule.rgb_autocontrast}
    - transform: NAGColorDrop
      params:
        p: ${datamodule.rgb_drop}

    # Add self-loops in the horizontal graph
    - transform: NAGAddSelfLoops

    # Compute the instance graph for instantiation
    # NB: setting `datamodule.instance: False` will skip this step
    - transform: OnTheFlyInstanceGraph
      params:
        level: ${eval:'1 if ${datamodule.instance} else -1'}
        num_classes: ${datamodule.num_classes}
        k_max: ${datamodule.instance_k_max}
        radius: ${datamodule.instance_radius}
        adjacency_mode: ${eval:'"radius-centroid" if ${datamodule.nano} else "radius-atomic"'}

    - transform: QuantizePointCoordinates
      params:
        size: ${eval:'${datamodule.voxel} if ${datamodule.quantize_coords} else -1'}

# GPU-based val transforms
on_device_val_transform:

    # Cast all attributes to either float or long. Doing this only now
    # allows speeding up disk I/O and CPU->GPU transfer
    - transform: NAGCast

    # Add a `node_size` attribute to all segments, this is needed for
    # segment-wise position normalization with UnitSphereNorm
    - transform: NodeSize
      params:
        low: 0

    # Compute some horizontal and vertical edges on-the-fly. Those are
    # only computed now since they can be deduced from point and node
    # attributes. Besides, the OnTheFlyHorizontalEdgeFeatures transform
    # takes a trimmed graph as input and doubles its size, creating j->i
    # for each input i->j edge
    - transform: OnTheFlyHorizontalEdgeFeatures
      params:
        keys: ${datamodule.edge_hf}
        use_mean_normal: ${eval:'"normal" in ${datamodule.segment_mean_hf}'}
    - transform: OnTheFlyVerticalEdgeFeatures
      params:
        keys: ${datamodule.v_edge_hf}
        use_mean_normal: ${eval:'"normal" in ${datamodule.segment_mean_hf}'}

    # RGB-specific transforms. In particular, the color dropout will
    # switch off all three color channels together, instead of just one
    # by one with
#    - transform: NAGColorNormalize
#      params:
#        level: 'all'
    # Add self-loops in the horizontal graph
    - transform: NAGAddSelfLoops

    # Compute the instance graph for instantiation
    # NB: setting `datamodule.instance: False` will skip this step
    - transform: OnTheFlyInstanceGraph
      params:
        level: ${eval:'1 if ${datamodule.instance} else -1'}
        num_classes: ${datamodule.num_classes}
        k_max: ${datamodule.instance_k_max}
        radius: ${datamodule.instance_radius}
        adjacency_mode: ${eval:'"radius-centroid" if ${datamodule.nano} else "radius-atomic"'}

    - transform: QuantizePointCoordinates
      params:
        size: ${eval:'${datamodule.voxel} if ${datamodule.quantize_coords} else -1'}

# GPU-based test transforms
on_device_test_transform: ${datamodule.on_device_val_transform}
